{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saumya Kothari - Natural Language Processing Project 1 (Part 1)\n",
    "\n",
    "## Part 1\n",
    "\n",
    "#### DOMAIN: \n",
    "Digital content management\n",
    "\n",
    "#### CONTEXT: \n",
    "Classification is probably the most popular task that you would deal with in real life. Text in the form of blogs, posts, articles,\n",
    "etc. is written every second. It is a challenge to predict the information about the writer without knowing about him/her. We are going to\n",
    "create a classifier that predicts multiple features of the author of a given text. We have designed it as a Multi label classification problem.\n",
    "\n",
    "#### DATA DESCRIPTION: \n",
    "Over 600,000 posts from more than 19 thousand bloggers The Blog Authorship Corpus consists of the collected\n",
    "posts of 19,320 bloggers gathered from blogger.com in August 2004. The corpus incorporates a total of 681,288 posts and over 140 million\n",
    "words - or approximately 35 posts and 7250 words per person. Each blog is presented as a separate file, the name of which indicates a\n",
    "blogger id# and the blogger’s self-provided gender, age, industry, and astrological sign. (All are labelled for gender and age but for many,\n",
    "industry and/or sign is marked as unknown.) All bloggers included in the corpus fall into one of three age groups:\n",
    "- 8240 \"10s\" blogs (ages 13-17),\n",
    "- 8086 \"20s\" blogs(ages 23-27) and\n",
    "- 2994 \"30s\" blogs (ages 33-47)\n",
    "For each age group, there is an equal number of male and female bloggers.\n",
    "Each blog in the corpus includes at least 200 occurrences of common English words. All formatting has been stripped with two exceptions.\n",
    "Individual posts within a single blogger are separated by the date of the following post and links within a post are denoted by the label url\n",
    "link. Link to dataset: https://www.kaggle.com/rtatman/blog-authorship-corpus\n",
    "\n",
    "#### PROJECT OBJECTIVE: \n",
    "The need is to build a NLP classifier which can use input text parameters to determine the label/s of the blog.\n",
    "Steps and tasks:\n",
    "1. Import and analyse the data set.\n",
    "2. Perform data pre-processing on the data:\n",
    "• Data cleansing by removing unwanted characters, spaces, stop words etc. Convert text to lowercase.\n",
    "• Target/label merger and transformation\n",
    "• Train and test split\n",
    "• Vectorisation, etc.\n",
    "3. Design, train, tune and test the best text classifier.\n",
    "4. Display and explain detail the classification report\n",
    "5. Print the true vs predicted labels for any 5 entries from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT NECESSARY PACKAGES\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import re # regular expression\n",
    "\n",
    "import nltk\n",
    "import os\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and analyse the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"blogtext.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>topic</th>\n",
       "      <th>sign</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>14,May,2004</td>\n",
       "      <td>Info has been found (+/- 100 pages,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>13,May,2004</td>\n",
       "      <td>These are the team members:   Drewe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>12,May,2004</td>\n",
       "      <td>In het kader van kernfusie op aarde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>12,May,2004</td>\n",
       "      <td>testing!!!  testing!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3581210</td>\n",
       "      <td>male</td>\n",
       "      <td>33</td>\n",
       "      <td>InvestmentBanking</td>\n",
       "      <td>Aquarius</td>\n",
       "      <td>11,June,2004</td>\n",
       "      <td>Thanks to Yahoo!'s Toolbar I can ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3581210</td>\n",
       "      <td>male</td>\n",
       "      <td>33</td>\n",
       "      <td>InvestmentBanking</td>\n",
       "      <td>Aquarius</td>\n",
       "      <td>10,June,2004</td>\n",
       "      <td>I had an interesting conversation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3581210</td>\n",
       "      <td>male</td>\n",
       "      <td>33</td>\n",
       "      <td>InvestmentBanking</td>\n",
       "      <td>Aquarius</td>\n",
       "      <td>10,June,2004</td>\n",
       "      <td>Somehow Coca-Cola has a way of su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3581210</td>\n",
       "      <td>male</td>\n",
       "      <td>33</td>\n",
       "      <td>InvestmentBanking</td>\n",
       "      <td>Aquarius</td>\n",
       "      <td>10,June,2004</td>\n",
       "      <td>If anything, Korea is a country o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3581210</td>\n",
       "      <td>male</td>\n",
       "      <td>33</td>\n",
       "      <td>InvestmentBanking</td>\n",
       "      <td>Aquarius</td>\n",
       "      <td>10,June,2004</td>\n",
       "      <td>Take a read of this news article ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3581210</td>\n",
       "      <td>male</td>\n",
       "      <td>33</td>\n",
       "      <td>InvestmentBanking</td>\n",
       "      <td>Aquarius</td>\n",
       "      <td>09,June,2004</td>\n",
       "      <td>I surf the English news sites a l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id gender  age              topic      sign          date  \\\n",
       "0  2059027   male   15            Student       Leo   14,May,2004   \n",
       "1  2059027   male   15            Student       Leo   13,May,2004   \n",
       "2  2059027   male   15            Student       Leo   12,May,2004   \n",
       "3  2059027   male   15            Student       Leo   12,May,2004   \n",
       "4  3581210   male   33  InvestmentBanking  Aquarius  11,June,2004   \n",
       "5  3581210   male   33  InvestmentBanking  Aquarius  10,June,2004   \n",
       "6  3581210   male   33  InvestmentBanking  Aquarius  10,June,2004   \n",
       "7  3581210   male   33  InvestmentBanking  Aquarius  10,June,2004   \n",
       "8  3581210   male   33  InvestmentBanking  Aquarius  10,June,2004   \n",
       "9  3581210   male   33  InvestmentBanking  Aquarius  09,June,2004   \n",
       "\n",
       "                                                text  \n",
       "0             Info has been found (+/- 100 pages,...  \n",
       "1             These are the team members:   Drewe...  \n",
       "2             In het kader van kernfusie op aarde...  \n",
       "3                   testing!!!  testing!!!            \n",
       "4               Thanks to Yahoo!'s Toolbar I can ...  \n",
       "5               I had an interesting conversation...  \n",
       "6               Somehow Coca-Cola has a way of su...  \n",
       "7               If anything, Korea is a country o...  \n",
       "8               Take a read of this news article ...  \n",
       "9               I surf the English news sites a l...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform data pre-processing on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id        False\n",
       "gender    False\n",
       "age       False\n",
       "topic     False\n",
       "sign      False\n",
       "date      False\n",
       "text      False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(681284, 7)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For easiness in computation and convinience, there are 68,124 records and is huge to perform analysis and computation, hence we are going to take a subset and rerun with the entire data-set once all errors are fixed and optimization is done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.head(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 7 columns):\n",
      "id        10000 non-null int64\n",
      "gender    10000 non-null object\n",
      "age       10000 non-null int64\n",
      "topic     10000 non-null object\n",
      "sign      10000 non-null object\n",
      "date      10000 non-null object\n",
      "text      10000 non-null object\n",
      "dtypes: int64(2), object(5)\n",
      "memory usage: 547.0+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data cleansing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['id','date'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns like ID and date are removed from the dataset as they do not provide much value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['age']=data['age'].astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 5 columns):\n",
      "gender    10000 non-null object\n",
      "age       10000 non-null object\n",
      "topic     10000 non-null object\n",
      "sign      10000 non-null object\n",
      "text      10000 non-null object\n",
      "dtypes: object(5)\n",
      "memory usage: 390.8+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()\n",
    "\n",
    "# from here we can see that all columns have been converted to object data type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing unwanted Characters, Spaces etc. Converting text to lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual data=======>            These are the team members:   Drewes van der Laag           urlLink mail  Ruiyu Xie                     urlLink mail  Bryan Aaldering (me)          urlLink mail          \n",
      "Cleaned data=======> these are the team members drewes van der laag urllink mail ruiyu xie urllink mail bryan aaldering me urllink mail\n"
     ]
    }
   ],
   "source": [
    "data['clean_data']=data['text'].apply(lambda x: re.sub(r'[^A-Za-z]+',' ',x)) # remove unwanted characters\n",
    "data['clean_data']=data['clean_data'].apply(lambda x: x.lower()) # convert to lowercase\n",
    "data['clean_data']=data['clean_data'].apply(lambda x: x.strip()) # removes unnecssary spaces\n",
    "print(\"Actual data=======> {}\".format(data['text'][1]))\n",
    "print(\"Cleaned data=======> {}\".format(data['clean_data'][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove all stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords=set(stopwords.words('english')) #setting stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'one thing love seoul mean korea general happen little seoul centric street sellers really trust food sell side road except ice cream virtually everything else fair game example get ready trip canada generally stock last two weeks bought plants nieces lightweight sports shirts inlining pair shorts inlining bags dried goguma sweet potatoes yams selling got tie amazing price usd really tell worse ones bought usd back home disposible razors usd ten noise making toy hammer boy disney photo albums sure ol walt make penny clothes seller guy spoke pretty good english know held hostage minutes talked korean men getting fatter hence stock larger sizes husky guys like learned english working us army years ago goguma guy know lot english speak spanish owing fact lived argentina years unfortunately spanish one languages know fair bit french school days smattering japanese course korean anyways passed goguma guy later week gave big hola spanish hello extent proficiency returned one well wow bridging cultures another one un picture famous yeouido tie truck guy stops hotspots unloads silk polyester ties neckwear hungry salarymen urllink usd'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['clean_data']=data['clean_data'].apply(lambda x: ' '.join([words for words in x.split() if words not in stopwords]))\n",
    "data['clean_data'][15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target/label merger and transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['labels']=data.apply(lambda col: [col['gender'],str(col['age']),col['topic'],col['sign']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>topic</th>\n",
       "      <th>sign</th>\n",
       "      <th>text</th>\n",
       "      <th>clean_data</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>Info has been found (+/- 100 pages,...</td>\n",
       "      <td>info found pages mb pdf files wait untill team...</td>\n",
       "      <td>[male, 15, Student, Leo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>These are the team members:   Drewe...</td>\n",
       "      <td>team members drewes van der laag urllink mail ...</td>\n",
       "      <td>[male, 15, Student, Leo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>In het kader van kernfusie op aarde...</td>\n",
       "      <td>het kader van kernfusie op aarde maak je eigen...</td>\n",
       "      <td>[male, 15, Student, Leo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>testing!!!  testing!!!</td>\n",
       "      <td>testing testing</td>\n",
       "      <td>[male, 15, Student, Leo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>male</td>\n",
       "      <td>33</td>\n",
       "      <td>InvestmentBanking</td>\n",
       "      <td>Aquarius</td>\n",
       "      <td>Thanks to Yahoo!'s Toolbar I can ...</td>\n",
       "      <td>thanks yahoo toolbar capture urls popups means...</td>\n",
       "      <td>[male, 33, InvestmentBanking, Aquarius]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  gender age              topic      sign  \\\n",
       "0   male  15            Student       Leo   \n",
       "1   male  15            Student       Leo   \n",
       "2   male  15            Student       Leo   \n",
       "3   male  15            Student       Leo   \n",
       "4   male  33  InvestmentBanking  Aquarius   \n",
       "\n",
       "                                                text  \\\n",
       "0             Info has been found (+/- 100 pages,...   \n",
       "1             These are the team members:   Drewe...   \n",
       "2             In het kader van kernfusie op aarde...   \n",
       "3                   testing!!!  testing!!!             \n",
       "4               Thanks to Yahoo!'s Toolbar I can ...   \n",
       "\n",
       "                                          clean_data  \\\n",
       "0  info found pages mb pdf files wait untill team...   \n",
       "1  team members drewes van der laag urllink mail ...   \n",
       "2  het kader van kernfusie op aarde maak je eigen...   \n",
       "3                                    testing testing   \n",
       "4  thanks yahoo toolbar capture urls popups means...   \n",
       "\n",
       "                                    labels  \n",
       "0                 [male, 15, Student, Leo]  \n",
       "1                 [male, 15, Student, Leo]  \n",
       "2                 [male, 15, Student, Leo]  \n",
       "3                 [male, 15, Student, Leo]  \n",
       "4  [male, 33, InvestmentBanking, Aquarius]  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data[['clean_data','labels']] #creating a new column called clean_data with the final clean labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_data</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>info found pages mb pdf files wait untill team...</td>\n",
       "      <td>[male, 15, Student, Leo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>team members drewes van der laag urllink mail ...</td>\n",
       "      <td>[male, 15, Student, Leo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>het kader van kernfusie op aarde maak je eigen...</td>\n",
       "      <td>[male, 15, Student, Leo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>testing testing</td>\n",
       "      <td>[male, 15, Student, Leo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>thanks yahoo toolbar capture urls popups means...</td>\n",
       "      <td>[male, 33, InvestmentBanking, Aquarius]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          clean_data  \\\n",
       "0  info found pages mb pdf files wait untill team...   \n",
       "1  team members drewes van der laag urllink mail ...   \n",
       "2  het kader van kernfusie op aarde maak je eigen...   \n",
       "3                                    testing testing   \n",
       "4  thanks yahoo toolbar capture urls popups means...   \n",
       "\n",
       "                                    labels  \n",
       "0                 [male, 15, Student, Leo]  \n",
       "1                 [male, 15, Student, Leo]  \n",
       "2                 [male, 15, Student, Leo]  \n",
       "3                 [male, 15, Student, Leo]  \n",
       "4  [male, 33, InvestmentBanking, Aquarius]  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data['clean_data']\n",
    "Y=data['labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count Vectorization with bi-grams and tri-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer=CountVectorizer(binary=True, ngram_range=(1,2))\n",
    "X=vectorizer.fit_transform(X)\n",
    "X[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aa', 'aa amazing', 'aa anger', 'aa compared', 'aa keeps']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'male': 5916,\n",
       " '15': 602,\n",
       " 'Student': 1137,\n",
       " 'Leo': 301,\n",
       " '33': 136,\n",
       " 'InvestmentBanking': 70,\n",
       " 'Aquarius': 571,\n",
       " 'female': 4084,\n",
       " '14': 212,\n",
       " 'indUnk': 3287,\n",
       " 'Aries': 4198,\n",
       " '25': 386,\n",
       " 'Capricorn': 215,\n",
       " '17': 1185,\n",
       " 'Gemini': 150,\n",
       " '23': 253,\n",
       " 'Non-Profit': 71,\n",
       " 'Cancer': 504,\n",
       " 'Banking': 16,\n",
       " '37': 33,\n",
       " 'Sagittarius': 1097,\n",
       " '26': 234,\n",
       " '24': 655,\n",
       " 'Scorpio': 971,\n",
       " '27': 1054,\n",
       " 'Education': 270,\n",
       " '45': 16,\n",
       " 'Engineering': 127,\n",
       " 'Libra': 491,\n",
       " 'Science': 63,\n",
       " '34': 553,\n",
       " '41': 20,\n",
       " 'Communications-Media': 99,\n",
       " 'BusinessServices': 91,\n",
       " 'Sports-Recreation': 80,\n",
       " 'Virgo': 236,\n",
       " 'Taurus': 812,\n",
       " 'Arts': 45,\n",
       " 'Pisces': 454,\n",
       " '44': 3,\n",
       " '16': 440,\n",
       " 'Internet': 118,\n",
       " 'Museums-Libraries': 17,\n",
       " 'Accounting': 4,\n",
       " '39': 79,\n",
       " '35': 2315,\n",
       " 'Technology': 2654,\n",
       " '36': 1708,\n",
       " 'Law': 11,\n",
       " '46': 7,\n",
       " 'Consulting': 21,\n",
       " 'Automotive': 14,\n",
       " '42': 14,\n",
       " 'Religion': 9,\n",
       " '13': 42,\n",
       " 'Fashion': 1622,\n",
       " '38': 46,\n",
       " '43': 6,\n",
       " 'Publishing': 4,\n",
       " '40': 1,\n",
       " 'Marketing': 156,\n",
       " 'LawEnforcement-Security': 10,\n",
       " 'HumanResources': 2,\n",
       " 'Telecommunications': 2}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_counts=dict()\n",
    "\n",
    "for labels in data.labels.values:\n",
    "    for label in labels:\n",
    "        if label in label_counts:\n",
    "            label_counts[label]+=1\n",
    "        else:\n",
    "            label_counts[label]=1\n",
    "            \n",
    "label_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "binarizer=MultiLabelBinarizer(classes=sorted(label_counts.keys()))\n",
    "Y=binarizer.fit_transform(data.labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the data into Test and Train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain,Xtest,Ytrain,Ytest=train_test_split(X,Y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Design, train, tune and test the best text classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=LogisticRegression(C=1.0, class_weight=None,\n",
       "                                                 dual=False, fit_intercept=True,\n",
       "                                                 intercept_scaling=1,\n",
       "                                                 l1_ratio=None, max_iter=100,\n",
       "                                                 multi_class='auto',\n",
       "                                                 n_jobs=None, penalty='l2',\n",
       "                                                 random_state=None,\n",
       "                                                 solver='lbfgs', tol=0.0001,\n",
       "                                                 verbose=0, warm_start=False),\n",
       "                    n_jobs=None)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=LogisticRegression(solver='lbfgs')\n",
    "model=OneVsRestClassifier(model)\n",
    "model.fit(Xtrain,Ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ypred=model.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ypred_inversed = binarizer.inverse_transform(Ypred)\n",
    "y_test_inversed = binarizer.inverse_transform(Ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display and explain detail the classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_evaluation_scores(Ytest, Ypred):\n",
    "    print('Accuracy score: ', accuracy_score(Ytest, Ypred))\n",
    "    print('F1 score: ', f1_score(Ytest, Ypred, average='micro'))\n",
    "    print('Average precision score: ', average_precision_score(Ytest, Ypred, average='micro'))\n",
    "    print('Average recall score: ', recall_score(Ytest, Ypred, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.3065\n",
      "F1 score:  0.6307253341342545\n",
      "Average precision score:  0.44431705998495674\n",
      "Average recall score:  0.525\n"
     ]
    }
   ],
   "source": [
    "print_evaluation_scores(Ytest, Ypred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print the true vs predicted labels for any 5 entries from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text:\t  (0, 593438)\t1\n",
      "  (0, 312628)\t1\n",
      "  (0, 421129)\t1\n",
      "  (0, 319058)\t1\n",
      "  (0, 449060)\t1\n",
      "  (0, 113776)\t1\n",
      "  (0, 529247)\t1\n",
      "  (0, 334172)\t1\n",
      "  (0, 567161)\t1\n",
      "  (0, 229515)\t1\n",
      "  (0, 586020)\t1\n",
      "  (0, 155847)\t1\n",
      "  (0, 375481)\t1\n",
      "  (0, 609968)\t1\n",
      "  (0, 170072)\t1\n",
      "  (0, 487526)\t1\n",
      "  (0, 442891)\t1\n",
      "  (0, 389210)\t1\n",
      "  (0, 440127)\t1\n",
      "  (0, 374716)\t1\n",
      "  (0, 154884)\t1\n",
      "  (0, 625081)\t1\n",
      "  (0, 150832)\t1\n",
      "  (0, 628568)\t1\n",
      "  (0, 258656)\t1\n",
      "  :\t:\n",
      "  (0, 587208)\t1\n",
      "  (0, 237653)\t1\n",
      "  (0, 100946)\t1\n",
      "  (0, 309458)\t1\n",
      "  (0, 161001)\t1\n",
      "  (0, 186471)\t1\n",
      "  (0, 445105)\t1\n",
      "  (0, 564389)\t1\n",
      "  (0, 146304)\t1\n",
      "  (0, 244114)\t1\n",
      "  (0, 637871)\t1\n",
      "  (0, 468706)\t1\n",
      "  (0, 148383)\t1\n",
      "  (0, 201242)\t1\n",
      "  (0, 155988)\t1\n",
      "  (0, 448370)\t1\n",
      "  (0, 100130)\t1\n",
      "  (0, 553035)\t1\n",
      "  (0, 336332)\t1\n",
      "  (0, 365564)\t1\n",
      "  (0, 100117)\t1\n",
      "  (0, 214330)\t1\n",
      "  (0, 562102)\t1\n",
      "  (0, 414403)\t1\n",
      "  (0, 81836)\t1\n",
      "True labels:\t27,Taurus,female,indUnk\n",
      "Predicted labels:\t24,Sagittarius,male\n",
      "\n",
      "\n",
      "Text:\t  (0, 374440)\t1\n",
      "  (0, 227615)\t1\n",
      "  (0, 552721)\t1\n",
      "  (0, 160777)\t1\n",
      "  (0, 248484)\t1\n",
      "  (0, 634422)\t1\n",
      "  (0, 565798)\t1\n",
      "  (0, 158733)\t1\n",
      "  (0, 49512)\t1\n",
      "  (0, 381212)\t1\n",
      "  (0, 565835)\t1\n",
      "  (0, 374555)\t1\n",
      "  (0, 159053)\t1\n",
      "  (0, 353497)\t1\n",
      "  (0, 49585)\t1\n",
      "  (0, 248581)\t1\n",
      "  (0, 160827)\t1\n",
      "  (0, 634610)\t1\n",
      "  (0, 353498)\t1\n",
      "  (0, 374561)\t1\n",
      "  (0, 374511)\t1\n",
      "  (0, 553080)\t1\n",
      "  (0, 381242)\t1\n",
      "True labels:\t35,Aries,Technology,male\n",
      "Predicted labels:\t35,Aries,Technology,male\n",
      "\n",
      "\n",
      "Text:\t  (0, 399759)\t1\n",
      "  (0, 487360)\t1\n",
      "  (0, 128843)\t1\n",
      "  (0, 312628)\t1\n",
      "  (0, 319058)\t1\n",
      "  (0, 449060)\t1\n",
      "  (0, 72520)\t1\n",
      "  (0, 541965)\t1\n",
      "  (0, 450189)\t1\n",
      "  (0, 192891)\t1\n",
      "  (0, 632385)\t1\n",
      "  (0, 446544)\t1\n",
      "  (0, 597026)\t1\n",
      "  (0, 334172)\t1\n",
      "  (0, 567161)\t1\n",
      "  (0, 248962)\t1\n",
      "  (0, 222683)\t1\n",
      "  (0, 611860)\t1\n",
      "  (0, 338994)\t1\n",
      "  (0, 586020)\t1\n",
      "  (0, 194964)\t1\n",
      "  (0, 244614)\t1\n",
      "  (0, 202270)\t1\n",
      "  (0, 418326)\t1\n",
      "  (0, 508880)\t1\n",
      "  :\t:\n",
      "  (0, 399802)\t1\n",
      "  (0, 414562)\t1\n",
      "  (0, 20454)\t1\n",
      "  (0, 60948)\t1\n",
      "  (0, 485323)\t1\n",
      "  (0, 47043)\t1\n",
      "  (0, 32293)\t1\n",
      "  (0, 318206)\t1\n",
      "  (0, 631997)\t1\n",
      "  (0, 239383)\t1\n",
      "  (0, 245841)\t1\n",
      "  (0, 103113)\t1\n",
      "  (0, 413349)\t1\n",
      "  (0, 451539)\t1\n",
      "  (0, 587656)\t1\n",
      "  (0, 247207)\t1\n",
      "  (0, 418393)\t1\n",
      "  (0, 311237)\t1\n",
      "  (0, 561212)\t1\n",
      "  (0, 509072)\t1\n",
      "  (0, 446758)\t1\n",
      "  (0, 443111)\t1\n",
      "  (0, 300739)\t1\n",
      "  (0, 348299)\t1\n",
      "  (0, 60971)\t1\n",
      "True labels:\t27,Aquarius,Education,female\n",
      "Predicted labels:\tfemale\n",
      "\n",
      "\n",
      "Text:\t  (0, 128843)\t1\n",
      "  (0, 312628)\t1\n",
      "  (0, 164559)\t1\n",
      "  (0, 477858)\t1\n",
      "  (0, 529247)\t1\n",
      "  (0, 375481)\t1\n",
      "  (0, 513546)\t1\n",
      "  (0, 31409)\t1\n",
      "  (0, 439440)\t1\n",
      "  (0, 562615)\t1\n",
      "  (0, 454077)\t1\n",
      "  (0, 20393)\t1\n",
      "  (0, 628568)\t1\n",
      "  (0, 363386)\t1\n",
      "  (0, 225428)\t1\n",
      "  (0, 422863)\t1\n",
      "  (0, 169199)\t1\n",
      "  (0, 341960)\t1\n",
      "  (0, 616967)\t1\n",
      "  (0, 173148)\t1\n",
      "  (0, 276924)\t1\n",
      "  (0, 294992)\t1\n",
      "  (0, 285158)\t1\n",
      "  (0, 187302)\t1\n",
      "  (0, 258888)\t1\n",
      "  :\t:\n",
      "  (0, 358347)\t1\n",
      "  (0, 169369)\t1\n",
      "  (0, 427566)\t1\n",
      "  (0, 489180)\t1\n",
      "  (0, 470405)\t1\n",
      "  (0, 43528)\t1\n",
      "  (0, 575414)\t1\n",
      "  (0, 96940)\t1\n",
      "  (0, 342341)\t1\n",
      "  (0, 439458)\t1\n",
      "  (0, 302491)\t1\n",
      "  (0, 518866)\t1\n",
      "  (0, 441310)\t1\n",
      "  (0, 364572)\t1\n",
      "  (0, 637190)\t1\n",
      "  (0, 538064)\t1\n",
      "  (0, 475878)\t1\n",
      "  (0, 290424)\t1\n",
      "  (0, 425899)\t1\n",
      "  (0, 153625)\t1\n",
      "  (0, 71656)\t1\n",
      "  (0, 425900)\t1\n",
      "  (0, 153648)\t1\n",
      "  (0, 431006)\t1\n",
      "  (0, 31419)\t1\n",
      "True labels:\t16,Pisces,Student,male\n",
      "Predicted labels:\t35,Aries,Technology,male\n",
      "\n",
      "\n",
      "Text:\t  (0, 312628)\t1\n",
      "  (0, 209803)\t1\n",
      "  (0, 334172)\t1\n",
      "  (0, 332005)\t1\n",
      "  (0, 586020)\t1\n",
      "  (0, 244614)\t1\n",
      "  (0, 375481)\t1\n",
      "  (0, 568960)\t1\n",
      "  (0, 256867)\t1\n",
      "  (0, 546404)\t1\n",
      "  (0, 417568)\t1\n",
      "  (0, 12710)\t1\n",
      "  (0, 45227)\t1\n",
      "  (0, 227615)\t1\n",
      "  (0, 628568)\t1\n",
      "  (0, 493821)\t1\n",
      "  (0, 368844)\t1\n",
      "  (0, 291623)\t1\n",
      "  (0, 241602)\t1\n",
      "  (0, 179466)\t1\n",
      "  (0, 616967)\t1\n",
      "  (0, 639750)\t1\n",
      "  (0, 332310)\t1\n",
      "  (0, 227048)\t1\n",
      "  (0, 342568)\t1\n",
      "  :\t:\n",
      "  (0, 128681)\t1\n",
      "  (0, 600743)\t1\n",
      "  (0, 428037)\t1\n",
      "  (0, 30374)\t1\n",
      "  (0, 117693)\t1\n",
      "  (0, 417821)\t1\n",
      "  (0, 242659)\t1\n",
      "  (0, 629184)\t1\n",
      "  (0, 383338)\t1\n",
      "  (0, 67406)\t1\n",
      "  (0, 93932)\t1\n",
      "  (0, 175546)\t1\n",
      "  (0, 260619)\t1\n",
      "  (0, 79066)\t1\n",
      "  (0, 237043)\t1\n",
      "  (0, 375486)\t1\n",
      "  (0, 4693)\t1\n",
      "  (0, 453542)\t1\n",
      "  (0, 141740)\t1\n",
      "  (0, 368863)\t1\n",
      "  (0, 244775)\t1\n",
      "  (0, 282568)\t1\n",
      "  (0, 436204)\t1\n",
      "  (0, 155275)\t1\n",
      "  (0, 257602)\t1\n",
      "True labels:\t27,Pisces,Technology,male\n",
      "Predicted labels:\tPisces,female\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print('Text:\\t{}\\nTrue labels:\\t{}\\nPredicted labels:\\t{}\\n\\n'.format(\n",
    "        Xtest[i],\n",
    "        ','.join(y_test_inversed[i]),\n",
    "        ','.join(Ypred_inversed[i])\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Important Notes:\n",
    "- I have solved Multilabel classification problem that predicts multiple features of the author of a given text\n",
    "- Loading the data and required basic EDA and data inspection has been done\n",
    "- The text has been pre processed like cleansing it(removing the unnecessary chars, removing the spaces, converting the case to lower) and also removing the stop words, vectorizing the features\n",
    "- Preparing the date, splitting them to train and test\n",
    "- Using multilable binarizers, also various classifier models are trained and the predictions are made and also the accuracy, f1 score, Avg precision and recall scores are calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
